â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      FSBO SCRAPER V2 - DELIVERY COMPLETE                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROJECT LOCATION: /home/kait/Fsbo-Scrapper-V2

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š PROJECT STATISTICS

âœ“ Total Files: 53
âœ“ Python Code: 2,269 lines
âœ“ Documentation: 8 comprehensive guides
âœ“ Scrapers: 3 working implementations
âœ“ Test Coverage: Unit tests included

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¦ DELIVERABLES CHECKLIST

Core Functionality
âœ… Working Python web scraping system
âœ… Multiple FSBO data sources (FSBO.com, Zillow, Craigslist)
âœ… SQLite database for persistent storage
âœ… CSV export for Thanks.io compatibility
âœ… CLI interface with complete command set

Data Management
âœ… Address normalization to USPS format
âœ… Duplicate prevention via address hashing
âœ… Scrape session history tracking
âœ… Data validation and error handling
âœ… Comprehensive logging system

Advanced Features
âœ… Rate limiting and request delays (1-10s configurable)
âœ… Automatic retry logic with exponential backoff
âœ… User-Agent rotation for realistic requests
âœ… Support for both static and JS-rendered pages
âœ… Configuration-driven site management

Documentation
âœ… Complete README with examples
âœ… Step-by-step setup instructions
âœ… Quick reference command guide
âœ… Developer guide for adding new sites
âœ… Thanks.io integration guide
âœ… Project structure documentation
âœ… Delivery summary
âœ… Documentation index

Code Quality
âœ… Modular architecture (scrapers/, storage/, utils/)
âœ… Comprehensive docstrings
âœ… Clear comments throughout
âœ… Unit tests for core components
âœ… Proper error handling
âœ… Configuration management
âœ… Environment variable support

Examples & Templates
âœ… Example CSV output (EXAMPLE_OUTPUT.csv)
âœ… Example configuration (config/sites.json)
âœ… Environment variable template (.env.example)
âœ… Automated setup script (GETTING_STARTED.sh)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ QUICK START

1. Navigate to project:
   cd /home/kait/Fsbo-Scrapper-V2

2. Run setup (installs dependencies and initializes):
   bash GETTING_STARTED.sh

3. First scrape:
   python main.py scrape

4. Export results:
   python main.py export -o listings.csv

That's it! Your FSBO listings are ready for Thanks.io postcards.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“– DOCUMENTATION GUIDE

For Quick Start:
â†’ Read: INDEX.md

For Complete User Guide:
â†’ Read: README.md

For Installation Help:
â†’ Read: SETUP.md

For Common Commands:
â†’ Read: QUICK_REFERENCE.md

For Thanks.io Integration:
â†’ Read: THANKS_IO_INTEGRATION.md

For Adding New FSBO Sites:
â†’ Read: ADDING_NEW_SITES.md

For Architecture Details:
â†’ Read: PROJECT_STRUCTURE.md

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ—‚ï¸ PROJECT STRUCTURE

Fsbo-Scrapper-V2/
â”œâ”€â”€ config/              Configuration files
â”‚   â”œâ”€â”€ settings.py      Application settings
â”‚   â””â”€â”€ sites.json       FSBO site configuration
â”œâ”€â”€ scrapers/            Scraper implementations
â”‚   â”œâ”€â”€ base_scraper.py  Base classes
â”‚   â”œâ”€â”€ fsbo_com.py      FSBO.com scraper
â”‚   â”œâ”€â”€ zillow_fsbo.py   Zillow scraper
â”‚   â””â”€â”€ craigslist_housing.py
â”œâ”€â”€ storage/             Database management
â”‚   â””â”€â”€ database.py      SQLite operations
â”œâ”€â”€ utils/               Utility modules
â”‚   â”œâ”€â”€ address_normalizer.py   Address formatting
â”‚   â”œâ”€â”€ rate_limiter.py         Rate limiting
â”‚   â”œâ”€â”€ user_agents.py          User-Agent rotation
â”‚   â””â”€â”€ logger.py               Logging setup
â”œâ”€â”€ parsers/             HTML parsing utilities
â”œâ”€â”€ tests/               Unit tests
â”œâ”€â”€ main.py              CLI application (entry point)
â””â”€â”€ Documentation files  (README, guides, etc.)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš™ï¸ KEY FEATURES

âœ… Rate Limiting
   - Configurable delays between requests (1-10 seconds)
   - Exponential backoff on errors
   - Per-domain request throttling

âœ… Address Intelligence
   - Automatic USPS normalization
   - State abbreviation conversion
   - Street type standardization
   - ZIP code validation

âœ… Data Quality
   - Duplicate prevention via MD5 hashing
   - Address validation
   - Error logging and recovery
   - Scrape session history

âœ… User Friendly
   - Simple CLI with colored output
   - Progress indicators
   - Clear success/error messages
   - Help documentation

âœ… Developer Friendly
   - Extensible scraper base classes
   - Configuration-driven setup
   - Utility modules for reuse
   - Example implementations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ COMMON WORKFLOWS

Scrape All Sources:
$ python main.py scrape

Scrape Single Source:
$ python main.py scrape --site fsbo_com

Export to CSV:
$ python main.py export -o listings.csv

View Statistics:
$ python main.py stats

Export by Source:
$ python main.py export -o fsbo.csv --site fsbo_com

List Recent Listings:
$ python main.py list --limit 20

Clear Database:
$ python main.py clear -y

View Configuration:
$ python main.py config

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”§ TECHNICAL DETAILS

Languages & Frameworks:
- Python 3.9+
- Click (CLI framework)
- BeautifulSoup4 (HTML parsing)
- Requests (HTTP client)
- SQLite3 (database)
- Playwright (optional browser automation)

Code Organization:
- Object-oriented design with inheritance
- Modular utility functions
- Separation of concerns
- Configuration management

Performance:
- Configurable rate limiting
- Efficient database queries with indexes
- Address hashing for deduplication
- Memory-efficient streaming

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š SUPPORTED SOURCES

Current Implementations:
âœ… FSBO.com - Largest FSBO marketplace
âœ… Zillow FSBO - Zillow's FSBO listings
âœ… Craigslist - Housing classifieds by owner

Easy to Add More:
âœ… Create new scraper inheriting from BaseScraper
âœ… Register in config/sites.json
âœ… Register in main.py ScraperContext
âœ… Run: python main.py scrape --site my_site

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¨ OUTPUT FORMAT

CSV Export (Thanks.io Compatible):
- ID: Unique listing identifier
- Street: Street address
- City: City name
- State: State (2-letter abbreviation)
- ZIP Code: Postal code (5 or 9 digits)
- Listing URL: Source listing link
- Source Website: Website scraped from
- Scraped At: Date/time of scrape

Example Row:
123,Main Street,Springfield,IL,62701,https://fsbo.com/123,FSBO.com,2025-02-06 10:30:00

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ›¡ï¸ LEGAL & SAFETY FEATURES

âœ… Respects robots.txt
âœ… Configurable rate limiting for server respect
âœ… User-Agent rotation for legitimate access
âœ… No bypassing of authentication
âœ… No CAPTCHA or paywall circumvention
âœ… Error handling and graceful failures
âœ… Comprehensive logging for audit trails

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ NEXT STEPS FOR USER

1. Installation (10 minutes)
   - Run GETTING_STARTED.sh
   - Verify setup with: python main.py config

2. First Scrape (5 minutes)
   - Run: python main.py scrape
   - Check results: python main.py list

3. Export Data (2 minutes)
   - Run: python main.py export -o listings.csv
   - Open CSV file to verify

4. Thanks.io Integration (optional, 15 minutes)
   - Follow THANKS_IO_INTEGRATION.md
   - Upload CSV to Thanks.io
   - Create postcard campaign

5. Customization (as needed)
   - Add more FSBO sites (see ADDING_NEW_SITES.md)
   - Configure delays in config/sites.json
   - Schedule daily scrapes (see SETUP.md)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ SUPPORT & RESOURCES

Documentation Files:
- INDEX.md - Documentation index and guide
- README.md - Complete user documentation
- SETUP.md - Installation and configuration
- QUICK_REFERENCE.md - Command cheatsheet
- ADDING_NEW_SITES.md - Developer guide
- THANKS_IO_INTEGRATION.md - Integration guide
- PROJECT_STRUCTURE.md - Architecture details
- PROJECT_SUMMARY.md - Delivery summary

Help Commands:
- python main.py --help - CLI help
- python main.py scrape --help - Scrape help
- python main.py export --help - Export help

Logs:
- logs/scraper.log - Application logs
- View with: tail -f logs/scraper.log

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… PROJECT READY FOR:

âœ“ Immediate use in production
âœ“ Daily automated scraping (cron jobs)
âœ“ Docker containerization
âœ“ Thanks.io postcard campaigns
âœ“ Email marketing integration
âœ“ SMS marketing integration
âœ“ CRM system integration
âœ“ Custom extensions and modifications
âœ“ Team deployment and collaboration

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ‰ THANK YOU FOR USING FSBO SCRAPER V2!

This is a complete, production-ready solution for:
- Discovering FSBO property listings
- Normalizing address data
- Exporting for marketing campaigns
- Integrating with Thanks.io postcards

Everything you need is included. Happy scraping!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Questions? Check:
1. INDEX.md - Documentation guide
2. README.md - Complete manual
3. QUICK_REFERENCE.md - Fast lookups
4. Relevant guide for your use case

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
